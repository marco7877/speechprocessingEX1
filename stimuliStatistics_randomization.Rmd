---
title: "StimuliStatistics"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE}
library("pacman")
pacman::p_load("dplyr","tidyr","readxl", "ggpubr")
## we are going to do bootstrap tp the amount of letters of the word. for this I am going to use the boot library
#pacman::p_load(tidyverse, dplyr, raster, ggplot2, rstatix, ggpubr, ggsignif,
               # MASS, RColorBrewer, psych,  emmeans,
              # corrplot, broom,rgl,  readxl,summarytools, caret)
```

```{r}
stimuli.all <- read.csv2("StimuliProposal_SpeechExperiment.csv",sep = ",")# load file
stimuli.all$sound <- as.character(stimuli.all$sound)
stimuli <- na.omit(as.data.frame(stimuli.all)) # delete NAs 
stimuli <- stimuli %>% dplyr::select(stimuli, category, condition, sound, corpes_norm_spain)# select variables of interest
stimuli$stimuli <- as.character(stimuli$stimuli) #change variables detected automatically as factor, to character
stimuli$category <- as.character(stimuli$category) #change variables detected automatically as factor, to character
stimuli.objects <- filter(stimuli, category=="objects")
stimuli.food <- filter(stimuli, category=="food")
stimuli.experiment <- rbind(stimuli.objects,stimuli.food)# this are the stimui we are going to use
#making a factor variable to make analysis easier
stimuli.experiment$sem.cat <- as.factor(stimuli.experiment$category)
```

```{r}
#plotting histogram and bosplot of distribution of general normalized frecuency
# making plot objects
general.hist <- hist(stimuli.experiment$corpes_norm_spain)
general.boxplot <- boxplot(stimuli.experiment$corpes_norm_spain)
####### actually plotting
plot(general.hist)
#general.boxplot
```
```{r}
#plotting individual semantic categories
hist.food <- hist(stimuli.food$corpes_norm_spain)
hist.object <- hist(stimuli.objects$corpes_norm_spain)
# side by side boxplots
joint.boxplot <- boxplot(stimuli.food$corpes_norm_spain, stimuli.objects$corpes_norm_spain)
# checking for normality
qqnorm(stimuli.experiment$corpes_norm_spain)
qqline(stimuli.experiment$corpes_norm_spain)
```

```{r}
#taking outliers out . Fromo graphical inspection it looks that for food the treshold > 60 and for objects the treshold > 40
## food
stimuli.food$outlier<-as.character(c(stimuli.food$corpes_norm_spain > 25))
stimuli.food.filtered <- dplyr::filter(stimuli.food, outlier=="FALSE")
mean(stimuli.food.filtered$corpes_norm_spain)
median(stimuli.food.filtered$corpes_norm_spain)
## objects
stimuli.objects$outlier <- as.character(c(stimuli.objects$corpes_norm_spain > 25))
stimuli.objects.filtered <- dplyr::filter(stimuli.objects, outlier == "FALSE")
mean(stimuli.objects.filtered$corpes_norm_spain)
median(stimuli.objects.filtered$corpes_norm_spain)
####### replotting boxplots
joint.boxplot.filtered <- boxplot(stimuli.food.filtered$corpes_norm_spain, stimuli.objects.filtered$corpes_norm_spain)
####### replotting qqplots
qqnorm(stimuli.food.filtered$corpes_norm_spain)
qqline(stimuli.food.filtered$corpes_norm_spain)
```

```{r}
# making contingency tables to see how many word we are going to replace
#creating counting variable first
#-- food
stimuli.food.filtered$element <- c("word")
food.contingency <- as.data.frame(
  table(
    stimuli.food.filtered$element, stimuli.food.filtered$sound))
names(food.contingency) <- c("stimuli.Level","sound","Freq")
stimuli.food.filtered$category <- as.factor(stimuli.food.filtered$category)
stimuli.food.filtered$mean <- mean(stimuli.food.filtered$corpes_norm_spain)
stimuli.food.filtered$median <- median(stimuli.food.filtered$corpes_norm_spain)
#-- object
stimuli.objects.filtered$element <- c("word")
object.contingency <- as.data.frame(
  table(
    stimuli.objects.filtered$element,
    stimuli.objects.filtered$sound))
names(object.contingency) <- c("stimuli.Level","sound","Freq")
stimuli.objects.filtered$category <- as.factor(stimuli.objects.filtered$category)
stimuli.objects.filtered$mean <- mean(stimuli.objects.filtered$corpes_norm_spain)
stimuli.objects.filtered$median <- median(stimuli.objects.filtered$corpes_norm_spain)
### merging filtered stimuli 
stimuli.experiment.filtered <- rbind(stimuli.food.filtered,stimuli.objects.filtered)
#stimuli.experiment.filtered$sem.cat <- as.factor(stimuli.experiment.filtered$category)
### saving data as .csv to manually eliminate stimuli 
#write.csv(stimuli.experiment.filtered,"stimuli_speechExperiment.csv", sep=",", row.names = F)
```

```{r,}
#making statistics with the data we have and looking to replace stimuli if needed
stimuli.experiment.filtered <-  read_excel("stimuli_speechExperiment.xlsx")
stimuli.experiment.filtered <- na.omit(stimuli.experiment.filtered)
#######
##
## We are reloading stimuli.objects.filtered and stimul.food.filtered
##
#######
stimuli.experiment.filtered$category <-as.character(stimuli.experiment.filtered$category) 
# counting characters 
stimuli.experiment.filtered$n.char <- nchar(as.character(stimuli.experiment.filtered$stimuli))
#
stimuli.objects.filtered <- filter(stimuli.experiment.filtered, category=="objects")
stimuli.food.filtered <- filter(stimuli.experiment.filtered, category=="food")

kruskal.food <- kruskal.test(stimuli.objects.filtered$corpes_norm_spain, stimuli.objects.filtered$condition)
kruskal.nfood <- kruskal.test(stimuli.objects.filtered$n.char, stimuli.objects.filtered$condition)

kruskal.objects <- kruskal.test(stimuli.objects.filtered$corpes_norm_spain, stimuli.objects.filtered$condition)
kruskal.nobjects <- kruskal.test(stimuli.objects.filtered$n.char, stimuli.objects.filtered$condition)

stimuli.experiment.filtered$sem.cat <- as.factor(stimuli.experiment.filtered$category)

#wilcox.test(codistrpes_norm_spain~sem.cat, data= stimuli.experiment.filtered)
###########
```



```{r}
boxplot(stimuli.food.filtered$corpes_norm_spain,stimuli.objects.filtered$corpes_norm_spain, xlab="semantic category", ylab="word frecuency (corpes)", names=c("food","objects"))
```

```{r}
#### ---- making plots with statistics 
## Food vs objects 
#- frecuency
stat.freq.foodObjects <-  stimuli.experiment.filtered %>% 
  wilcox_test(corpes_norm_spain ~ category, paired = F, exact = T) %>%
  add_significance()
boxplot1 <- ggboxplot(stimuli.experiment.filtered,x="category",y="corpes_norm_spain", palette = get_palette(c("#ffffff", "#ffffff"), 2),
         ylab= "Frequency (corpes)",xlab="Semantic Category")
stat.freq.foodObjects <-  stat.freq.foodObjects %>% add_xy_position(x = "group")
boxplot1 <- boxplot1+stat_pvalue_manual(stat.freq.foodObjects, tip.length = 0) +
labs(subtitle = get_test_label(stat.freq.foodObjects, detailed= T))
#-letters
stat.lett.foodObjects <-  stimuli.experiment.filtered %>% 
  wilcox_test(n.char ~ category, paired = F, exact = T) %>%
  add_significance()
boxplot2 <- ggboxplot(stimuli.experiment.filtered,x="category",y="n.char", palette = get_palette(c("#ffffff", "#ffffff"), 2),
         ylab= "lenght (letters)",xlab="Semantic Category")
stat.lett.foodObjects <-  stat.lett.foodObjects %>% add_xy_position(x = "group")
boxplot2 <- boxplot2+stat_pvalue_manual(stat.lett.foodObjects, tip.length = 0) +
labs(subtitle = get_test_label(stat.lett.foodObjects, detailed= T))

```

```{r}
#### ---- making plots with statistics 
## Mode of articulation
#- frecuency
boxplot3 <- ggboxplot(stimuli.experiment.filtered,x="condition",y="corpes_norm_spain",
         ylab= "Frequency (corpes)",xlab="Mode of articulation")+
  stat_compare_means()
#- letters
boxplot4 <- ggboxplot(stimuli.experiment.filtered,x="condition",y="n.char",
         ylab= "length (letters)",xlab="Mode of articulation")+
  stat_compare_means()
## letter
#- frecuency
boxplot5 <- ggboxplot(stimuli.experiment.filtered,x="sound",y="corpes_norm_spain",
         ylab= "Frequency (corpes)",xlab="First sound")+
  stat_compare_means()
#- letters
boxplot6 <- ggboxplot(stimuli.experiment.filtered,x="sound",y="n.char",
         ylab= "length (letters)",xlab="First sound")+
  stat_compare_means()
```



```{r}
#deciding how to make non word stimuli. We will do:
#-Count the amount of characters in our words
#-determine the mean and the SD of the character length distribution
#-sample the amount of characters from the afforementioned distribution (bootstraping) -> boot library
#- convert amount of characters to actual n(X) strings

#########################################################
set.seed(7877)# for replicating purposes of sampling
n_targetcontrolwords <- 10 # for run
word_sample <- as.data.frame( replicate(1000,sample(stimuli.experiment.filtered$n.char,n_targetcontrolwords, replace = T)))
sample_indexes <-sample(c(1:1000))
n_sessions <- 1 # amount of desired run sessions
sample_indexes <- sample_indexes[1:n_sessions]

## note: Sample_indexes is a list of n=>1, we need to transform integers to factors for R to effectively use them to localize columns
word_sample <- word_sample[,as.factor(sample_indexes)]
## note: As we may have several columns depending on the runs,
#        we are using tidr::gather to rbind them. Then we use #        the second column, because the output from gather is:
#        column name, value
word_sample <- tidyr::gather(as.data.frame(word_sample))[2]
names(word_sample) <- c("num") #we are renaming our remaining
#### Creating stimuli 
word_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(word_sample[,1])){word_sample 
word_sample$wordControl[i] <- strrep("x",word_sample$num[i])}
#

## load sentences
SentencesSubject <- read_excel("SentencesSubject.xlsx")
# s1
SentencesSubject$nfirst <- nchar(as.character(SentencesSubject$S1))
# s2
## we already have our control "targets"
# s3
SentencesSubject$nthird <- nchar(as.character(SentencesSubject$S3))
# s4
SentencesSubject$nfourth <- nchar(as.character(SentencesSubject$S4))
# s5
SentencesSubject$nfifth <- nchar(as.character(SentencesSubject$S5))
# s6
SentencesSubject$nsixth <- nchar(as.character(SentencesSubject$S6))
## make replaements from sample 
n_targetcontrolsentences <- 10 # for run
# s1
ns1_sample <- as.data.frame( replicate(1000,sample(SentencesSubject$nfirst,n_targetcontrolsentences, replace = T)))
# s2
## we done this in previous lines (word condition)
# s3
ns3_sample <- as.data.frame( replicate(1000,sample(SentencesSubject$nthird,n_targetcontrolsentences, replace = T)))
# s4
ns4_sample <- as.data.frame( replicate(1000,sample(SentencesSubject$nfourth,n_targetcontrolsentences, replace = T)))
# s5
ns5_sample <- as.data.frame( replicate(1000,sample(SentencesSubject$nfifth,n_targetcontrolsentences, replace = T)))
# s6
ns6_sample <- as.data.frame( replicate(1000,sample(SentencesSubject$nsixth,n_targetcontrolsentences, replace = T)))
## we are using the same indexes as in the word control condition

############## create words
## note: Sample_indexes is a list of n=>1, we need to transform integers to factors for R to effectively use them to localize columns
###
# ns1
ns1_sample <- ns1_sample[,as.factor(sample_indexes)]
ns1_sample <- tidyr::gather(as.data.frame(ns1_sample))[2]
ns1_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(ns1_sample[,1])){ns1_sample$wordControl[i] <- strrep("x",ns1_sample$value[i])}

###
# ns3
ns3_sample <- ns3_sample[,as.factor(sample_indexes)]
ns3_sample <- tidyr::gather(as.data.frame(ns3_sample))[2]
ns3_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(ns3_sample[,1])){ns3_sample$wordControl[i] <- strrep("x",ns3_sample$value[i])}
###
# ns4
ns4_sample <- ns4_sample[,as.factor(sample_indexes)]
ns4_sample <- tidyr::gather(as.data.frame(ns4_sample))[2]
ns4_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(ns4_sample[,1])){ns4_sample$wordControl[i] <- strrep("x",ns4_sample$value[i])}
###
# ns5
ns5_sample <- ns5_sample[,as.factor(sample_indexes)]
ns5_sample <- tidyr::gather(as.data.frame(ns5_sample))[2]
ns5_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(ns5_sample[,1])){ns5_sample$wordControl[i] <- strrep("x",ns5_sample$value[i])}
###
# ns6
ns6_sample <- ns6_sample[,as.factor(sample_indexes)]
ns6_sample <- tidyr::gather(as.data.frame(ns6_sample))[2]
ns6_sample$wordControl <- c("")#empty string variable
#repeat x required n times 
for (i in 1:length(ns6_sample[,1])){ns6_sample$wordControl[i] <- strrep("x",ns6_sample$value[i])}
```


```{r}
## We are going to use this chunk of code to merge all the data we already have and put it into a general csv
namesdf <- names(stimuli.experiment.filtered)
namesdf <- namesdf[1:10]
stimuli.experiment.filtered <- stimuli.experiment.filtered[,as.factor(namesdf)]
as
namessentences <- names(SentencesSubject)
namessentences <- namessentences[1:8]
SentencesSubject <- SentencesSubject[,as.factor(namessentences)]
# --words
control_new <- data.frame(word_sample$wordControl)
names(control_new) <- c("stimuli")
control_new$category <- c("control")
control_new$condition <- c("control")
control_new$sound <- c(NaN)
control_new$corpes_norm_spain <- c(NaN)
control_new$outlier <- c("FALSE")
control_new$element <- c("word_control")
control_new$mean <- c(NaN)
control_new$median <- c(NaN)
control_new$n.char <- word_sample$num
#sentences
sentences <- data.frame(word_sample$wordControl,c(6),ns1_sample$wordControl,word_sample$wordControl,ns3_sample$wordControl,ns4_sample$wordControl,ns5_sample$wordControl,ns6_sample$wordControl)
#
stimuli.experiment.filtered <- rbind(stimuli.experiment.filtered,control_new)
#
names(sentences) <- names(SentencesSubject)
SentencesSubject <- rbind(SentencesSubject,sentences)
#### merging sentences with word stimuli by stimuli
#test <- merge(stimuli.experiment.filtered,SentencesSubject,by="stimuli")
#write.csv(test,"completeStimuli_Exp1.csv",fileEncoding = "UTF-8")
```

```{r}
boxplot7 <- ggboxplot(stimuli.experiment.filtered,x="sound",y="n.char",
         ylab= "length (letters)",xlab="First sound")+
  stat_compare_means()
```

```{r}
## getting unique elements in sentences
sentences <- read_excel("./Stimuli_Exp1_subselection.xlsx")%>%
  dplyr::select("S1","S2","S3","S4","S5","S6","status")
acceptedSentence_mask <- sentences$status==1
sentences <-sentences[acceptedSentence_mask,]
one <- unique(sentences$S1)
two<- unique(sentences$S2)
three<- unique(sentences$S3)
four<- unique(sentences$S4)
five<- unique(sentences$S5)
six<- unique(sentences$S6)
wordsSentence <- c(one,two,three,four,five,six)
wordsSentence <- as.data.frame(wordsSentence)
wordsSentence <- unique(wordsSentence)
write.csv(wordsSentence,"tokens4SentencesStimuli.csv",sep=",")
```




