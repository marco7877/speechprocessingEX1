---
title: "stimuli_presentation"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE}
library(knitr, pacman)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(stringr, dplyr, readxl)
```

```{r}
set.seed(1)
stimuliOcurrence <- 10
#originFiles <- list.files("~/Documents/experiment1/secuences/",full.names = F)
originFiles <- list.files("~/Documents/experiment1/BalancedFdFe_TR1200/",pattern ="Speech_wordLevel11_*",full.names = F)
extention="balancedSequence.csv"
steps <- length(originFiles)%/%2
xfiles <- str_remove_all(originFiles,"nEvents.csv")
xfiles <- str_remove_all(xfiles,"BestList.csv")
xfiles <- unique(xfiles)
#xfiles2 <- str_remove_all(xfiles,"secuences")
#############--- Loop
for (i in 1:steps)
  {
file_lists <- read.csv2(paste("./BalancedFdFe_TR1200/",xfiles[i],"BestList.csv",sep="") , header = F, sep = ",")+1
file_n <- read.csv2(paste("./BalancedFdFe_TR1200/",xfiles[i],"nEvents.csv",sep=""), header = F, sep = ",")
names(file_n) <- as.factor(c(1:length(file_n)))
over <- file_n>10
under <- file_n<10
n_over <- (sum(file_n[,over])%%stimuliOcurrence)
over_indexes <- (as.numeric(names(file_n)))[over]#logical of
# n elements that met condition >stimuliOcurrence
over_indexes <- sample(which(ifelse(file_lists[,1] %in% over_indexes,T,F)),as.numeric(n_over))# indentify indexes, make a sample of the aforementioned and extract a sample of them of equal length as the amount of elements that are more than expected
## DISCLAIMER-> this only works because We have an overload of ##      0s, if not, it will fail. Esto deber√≠a de ser otro for

#extracting negative difference
x <- data.frame(matrix(ncol=2,nrow=sum(under)))
x[,1] <- names(file_n)[under]
x[,2] <- (file_n-10)[under]*-1
replace_elements <- as.numeric(rep(x[,1],times=x[,2]))#making list of elements to change
file_lists[over_indexes,] <- replace_elements#replacing elements that lack n representations in file_list
######################
if (!dir.exists("./output")){
  dir.create("./output")
}
names(file_lists) <- "elementType"
write.csv2(file_lists, paste("./output/",xfiles[i],extention,sep = ""),row.names = F)
}

```

```{r, eval=FALSE}
set.seed(2)
word <- read.csv2("wordStimuli.csv", sep = ",")
word <- word%>%arrange(desc(stimuli)) 
word$soundf <- as.factor(word$sound )
levels(word$soundf) <- c("6","5","2","3","1","4","7")
word$soundindex <- as.integer(as.character(word$soundf))
orders <- read.csv2("./output/Speech_wordLevel11_6192023-1146_balancedSequence.csv")
orders$token <- c("")
orders$sem <- c("")
for (i in 1:7){
  listindex <- orders$elementType==i
  stimulitarget <- word%>%filter( soundindex==i) %>% select(stimuli,sem)
  #stimulitarget <- word%>%filter( soundindex==i) 
  #stimulitarget$stimuli <- sample(as.character(stimulitarget$stimuli))
  stimulitarget <- sample(stimulitarget)
  stimulitarget$stimuli <- as.character(stimulitarget$stimuli)
  stimulitarget$sem <- as.character(stimulitarget$sem)
  orders$token[listindex] <- stimulitarget$stimuli
  orders$sem[listindex] <- stimulitarget$sem
}
#write.csv2(orders,"./output/4BalancedWordSequence.csv",row.names = F, sep = ",")
### now we are making n amount of different word sequences 
nVariants <- 3#amount of different sequences beside the base one
uniqueSem <- unique(orders$sem)
for (i in 1:nVariants){
  tmpOrders <- orders
  for (j in uniqueSem)
  { print(j)
    semindex <- orders$sem==j
    tmp <- sample(orders$token[semindex])
    tmpOrders$token[semindex] <- tmp
  }
  write.csv2(tmpOrders,paste("./output/",as.character(i), "BalancedWordSequence.csv",sep = ""),row.names = F, sep = ",")
}
```

```{r}
set.seed(3)
sequences <- 4
syllable <- read.csv2("syllableStimuli.csv", sep = ",")
syllable <- syllable%>%arrange(desc(stimuli)) 
syllable$soundf <- as.factor(syllable$sound )
levels(syllable$soundf) <- c("7","2","3","4","5","6","1")
syllable$soundindex <- as.integer(as.character(syllable$soundf))
orders <- read.csv2("./output/Speech_wordLevel11_6192023-1146_balancedSequence.csv")
orders$token <- c("")
for (j in 1:sequences){
for (i in 1:7){
  listindex <- orders$elementType==i
  stimulitarget <- syllable%>%filter( soundindex==i) %>% select(stimuli)
  stimulitarget$stimuli <- sample(as.character(stimulitarget$stimuli))
  orders$token[listindex] <- stimulitarget$stimuli
}
write.csv2(orders,paste("./output/",as.character(j),"BalancedSyllableSequence.csv",sep = ","),row.names = F)
}
```



```{r}

set.seed(4)
sentence <- read.csv2("wordStimuli.csv", sep = ",")
sentence <- sentence%>%arrange(desc(stimuli)) 
sentence$soundf <- as.factor(sentence$sound )
levels(sentence$soundf) <- c("7","3","4","5","6","1","2")
sentence$soundindex <- as.integer(as.character(sentence$soundf))
orders <- read.csv2("./output/Speech_wordLevel11_6192023-1146_balancedSequence.csv")
orders$token <- c("")
orders$sem <- c("")
for (i in 1:7){
  listindex <- orders$elementType==i
  stimulitarget <- sentence%>%filter( soundindex==i) %>% select(stimuli,sem)
  #stimulitarget <- word%>%filter( soundindex==i) 
  #stimulitarget$stimuli <- sample(as.character(stimulitarget$stimuli))
  stimulitarget <- sample(stimulitarget)
  stimulitarget$stimuli <- as.character(stimulitarget$stimuli)
  stimulitarget$sem <- as.character(stimulitarget$sem)
  orders$token[listindex] <- stimulitarget$stimuli
  orders$sem[listindex] <- stimulitarget$sem
}
#write.csv2(orders,"./output/4BalancedWordSequence.csv",row.names = F, sep = ",")
### now we are making n amount of different word sequences 
nVariants <- 4#amount of different sequences beside the base one
uniqueSem <- unique(orders$sem)
sentenceList <- read_excel("./Stimuli_Exp1_subselection.xlsx")%>%
  dplyr::select("S1","S2","S3","S4","S5","S6","status")
acceptedSentence_mask <- sentenceList$status==1
sentenceList <-sentenceList[acceptedSentence_mask,]
Sentencetmp <-as.data.frame( paste(sentenceList$S1,sentenceList$S2,
                       sentenceList$S3,sentenceList$S4,
                       sentenceList$S5,sentenceList$S6,
                       sep = " "))
Sentencetmp$token <- sentenceList$S2
names(Sentencetmp) <-c("stimuli","token") 
Sentencetmp <-merge(Sentencetmp,orders,by="token") 
Sentencetmp <- Sentencetmp[1:70,]
Sentencetmp$stimuli <- as.character(Sentencetmp$stimuli)
for (i in 1:nVariants)
  {
  tmpOrders <- orders
  tmpSentence <- Sentencetmp
  for (j in uniqueSem)
  { 
    semindex <- orders$sem==j
    tmp <- sample(Sentencetmp[Sentencetmp$sem==j,])
    tmpOrders$token[semindex] <- tmp$stimuli
  }
  
  write.csv2(tmpOrders,paste("./output/",as.character(i),"BalancedSentenceSequence.csv",sep = ""),row.names = F)
  }

```

